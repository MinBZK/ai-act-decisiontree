version: 1.0.0
name: Decision Tree
questions:

### root: definitie algoritme ARK
- questionId: '0'
  question: Voldoet je algoritme aan de definitie van 'algoritme' van de ARK? 'Een set van regels en instructies die een computer geautomatiseerd volgt bij het maken van berekeningen om een probleem op te lossen of een vraag te beantwoorden.'
  questionType: SingleChoice
  answers:
  - answer: Ja
    nextQuestionId: '1.0'
  - answer: Nee
    result: Je gebruikt geen algoritme. Houd je wel aan bestaande wet- en regelgeving (bijv. AVG wanneer je persoonsgegevens verwerkt) # Bak A: geen algoritme

### definitie AI systeem
- questionId: '1.0'
  question: 'Betreft je algoritme een AI-systeem volgens definitie AI-verordening? Daarbij kan gebruik worden gemaakt van de volgende definities uit artikel 3 van de AI-verordening:

    ''AI-systeem'': een op een machine gebaseerd systeem dat is ontworpen om met verschillende niveaus van autonomie te werken en dat na het inzetten ervan aanpassingsvermogen kan vertonen, en dat, voor expliciete of impliciete doelstellingen, uit de ontvangen input afleidt hoe output te genereren zoals voorspellingen, inhoud,aanbevelingen of beslissingen die van invloed kunnen zijn op fysieke of virtuele omgevingen

    ''AI-systeem voor algemene doeleinden'': een AI-systeem dat is gebaseerd op een AI-model voor algemene doeleinden en dat verschillende doeleinden kan dienen, zowel voor direct gebruik als voor integratie in andere AI-systemen'
  questionType: MultipleChoice
  answers:
  - answer: Ja, het betreft een AI-systeem, maar geen AI-systeem voor algemene doeleinden
    nextQuestionId: '2.0'
  - answer: Ja, het betreft een AI-systeem voor algemene doeleinden
    nextQuestionId: '7.0'
  - answer: Nee
    nextQuestionId: '9.0'

### reikwijdte AI verordening
- questionId: '2.0'
  question: 'Bepaal reikwijdte AI-verordening. Is het antwoord op alle volgende vragen Nee? Dan is de AI-verordening van Toepassing. Vragen:

    1. Zal je AI-systeem of de output van het systeem uitsluitend in de handel wordt gebracht, in gebruik worden gesteld of - al dan niet gewijzigd - worden gebruikt voor militaire, defensie- of nationale veiligheidsdoeleinden, ongeacht het soort entiteit dat deze activiteiten uitvoert?

    2. Ga je een AI-systeem ontwikkelen, maar alleen met wetenschappelijk onderzoek als enig doel?

    3. Ben je momenteel, of ga je binnekort beginnen met onderzoeks-, test- of ontwikkelingsactiviteiten met betrekking tot AI-systemen of AI-modellen voor zij in de handel worden gebracht of in gebruik worden gesteld?

    4. Ga je een AI-systeem ontwikkelen die gratis beschikbaar wordt gesteld of vrijgegeven onder opensourcelicenties?'
  questionType: SingleChoice
  answers:
  - answer: Het antwoord op alle vier de vragen is Nee
    answerComment: "De AI-verordening is van toepassing."
    nextQuestionId: '3.0'
  - answer: "\xC9\xE9n of meer vragen zijn met Ja beantwoord"
    answerComment: "De AI-verordening is niet van toepassing"
    nextQuestionId: '9.0'

### Verboden AI systemen
- questionId: '3.0'
  question: We gaan bepalen of je AI-systeem valt onder de verboden systemen van artikel 5 van de AI-verordening. Zou je AI-systeem gebruik kunnen gaan maken van subliminale technieken om mensen onbewust of bewust kunnen manipuleren, waardoor ze beslissingen nemen die ze anders niet zouden hebben genomen?
  questionType: SingleChoice
  answers:
  - answer: Ja
    result: Deze type AI-systemen zijn in principe verboden volgens de AI-verordening. We adviseren om contact te maken met....om dit verder te bekijken ... # Bak B: verboden AI
  - answer: Nee
    nextQuestionId: '3.1'
- questionId: '3.1'
  question: Zou je AI-systeem gebruik kunnen gaan maken van kwetsbaarheden van individuen of specifieke groepen, zoals leeftijd, handicaps of sociale/economische omstandigheden, om het gedrag van die personen aanzienlijk te verstoren, wat kan leiden tot aanzienlijke schade bij henzelf of anderen?
  questionType: SingleChoice
  answers:
  - answer: Ja
    result: Deze type AI-systemen zijn in principe verboden volgens de AI-verordening. We adviseren om contact te maken met....om dit verder te bekijken ... # Bak B: verboden AI
  - answer: Nee
    nextQuestionId: '3.2'
- questionId: '3.2'
  question: Zou je AI-systemen gebruikt kunnen worden om natuurlijke personen of groepen gedurende een periode te evalueren of te classificeren op basis van hun sociale gedrag of afgeleide persoonlijke kenmerken? Dit kan leiden tot nadelige behandelingen die niet gerechtvaardigd zijn en geen verband houden met de oorspronkelijke context van de data of met de ernst van het sociale gedrag.
  questionType: SingleChoice
  answers:
  - answer: Ja
    result: Deze type AI-systemen zijn in principe verboden volgens de AI-verordening. We adviseren om contact te maken met....om dit verder te bekijken ... # Bak B: verboden AI
  - answer: Nee
    nextQuestionId: '3.3'
- questionId: '3.3'
  question: Zou je AI-systeem gebruikt kunnen worden voor risicobeoordelingen van natuurlijke personen om het risico op crimineel gedrag te voorspellen, gebaseerd op profilering of persoonlijkheidskenmerken? Dit geldt niet voor AI-systemen die worden gebruikt om menselijke beoordelingen te ondersteunen, gebaseerd op objectieve en verifieerbare feiten die rechtstreeks verband houden met criminele activiteiten.
  questionType: SingleChoice
  answers:
  - answer: Ja
    result: Deze type AI-systemen zijn in principe verboden volgens de AI-verordening. We adviseren om contact te maken met....om dit verder te bekijken ... # Bak B: verboden AI
  - answer: Nee
    nextQuestionId: '3.4'
- questionId: '3.4'
  question: Zou je AI-systemen gebruikt kunnen worden om databanken voor gezichtsherkenning aan te leggen of aan te vullen door willkeurige gezichtsafbeeldingen van internet of CCTV-beelden te scrapen?
  questionType: SingleChoice
  answers:
  - answer: Ja
    result: Deze type AI-systemen zijn in principe verboden volgens de AI-verordening. We adviseren om contact te maken met....om dit verder te bekijken ... # Bak B: verboden AI
  - answer: Nee
    nextQuestionId: '3.5'
- questionId: '3.5'
  question: Zou je AI-systemen gebruik kunnen worden om emoties van een persoon op de werkplek of in het onderwijs af te leiden? Dit is niet van toepassing als het gebruik van het AI-systeem is bedoeld voor medische- of veiligheidsdoeleinden.
  questionType: SingleChoice
  answers:
  - answer: Ja
    result: Deze type AI-systemen zijn in principe verboden volgens de AI-verordening. We adviseren om contact te maken met....om dit verder te bekijken ... # Bak B: verboden AI
  - answer: Nee
    nextQuestionId: '3.6'
- questionId: '3.6'
  question: "Zou je AI-systemen gebruikt kunnen worden om natuurlijke personen individueel in categorie\xEBn in te delen op basis van biometrische gegevens om ras, politieke opvattingen, lidmaatschap van een vakbond, religieuze of levensbeschouwelijke overtuigingen, seksleven of seksuele geaardheid af te leiden? Dit verbod geldt niet voor het labelen of filteren van rechtmatig verkregen biometrische datasets, zoals afbeeldingen, op basis van biometrische gegevens, of voor categorisering van biometrische gegevens op het gebied van rechtshandhaving."
  questionType: SingleChoice
  answers:
  - answer: Ja
    result: Deze type AI-systemen zijn in principe verboden volgens de AI-verordening. We adviseren om contact te maken met....om dit verder te bekijken ... # Bak B: verboden AI
  - answer: Nee
    nextQuestionId: '3.7'
- questionId: '3.7'
  question: "Zou je AI-systeem gebruik kunnen worden voor biometrische identificatie op afstand in real time in openbare ruimten met het oog op de rechtshandhaving? Dit geldt niet als het systeem strikt noodzakelijk is voor een van de volgende doelen:\ni) Gericht zoeken naar specifieke slachtoffers van ontvoering, mensenhandel of seksuele uitbuiting, evenals het zoeken naar vermiste personen.\nii) Voorkomen van een specifieke, aanzienlijke en onmiddellijke dreiging voor het leven of de fysieke veiligheid van personen, of een re\xEBle en actuele of voorspelbare dreiging van een terroristische aanslag.\niii) Lokalisatie of identificatie van een persoon die verdacht wordt van het plegen van een strafbaar feit, voor strafrechtelijk onderzoek of vervolging, met een maximale straf van ten minste vier jaar vrijheidsbeneming zoals vermeld in bijlage II van de betrokken lidstaat."
  questionType: SingleChoice
  answers:
  - answer: Ja
    result: Deze type AI-systemen zijn in principe verboden volgens de AI-verordening. We adviseren om contact te maken met....om dit verder te bekijken ... # Bak B: verboden AI
  - answer: Nee
    answerComment: Het lijkt er op dat je AI-systeem geen verboden systeem is. We gaan nu bepalen of het systeem valt onder de hoog-risico categorisatie van de AI-verordening.
    nextQuestionId: '4.0'

### Hoog risico AI Act - bijlage I
- questionId: '4.0'
  question: Is het AI-systeem bedoeld om te worden gebruikt als veiligheidscomponent van een product of is het AI-systeem zelf een product dat valt onder de in bijlage I van de AI-verordening (link) opgenomen harmonisatiewetgeving van de Unie?
  questionType: SingleChoice
  answers:
  - answer: Ja
    answerComment: Je AI-systeem wordt waarschijnlijk beschouwd als een hoog-risico AI-systeem en moet voldoen aan bepaalde vereisten. We gaan nu bepalen welke rol je hebt om te bepalen aan welke vereisten je moet voldoen.
    nextQuestionId: '4.2.0'
  - answer: Nee
    nextQuestionId: '4.1'
- questionId: '4.1'
  question: Moet het product waarvan het AI-systeem de veiligheidscomponent vormt een conformiteits-beoordeling door een derde partij laten uitgevoeren met het oog op het in de handel brengen of in gebruik stellen van dat product op grond van de in bijlage I opgenomen harmonisatiewetgeving van de Unie?
  questionType: SingleChoice
  answers:
  - answer: Ja
    answerComment: Je AI-systeem wordt waarschijnlijk beschouwd als een hoog-risico AI-systeem en moet voldoen aan bepaalde vereisten. We gaan nu bepalen welke rol je hebt om te bepalen aan welke vereisten je moet voldoen.
    nextQuestionId: '4.2.0'
  - answer: Nee
    nextQuestionId: '5.0'

### Check rol bij hoog risico - bijlage I
- questionId: '4.2.0'
  question: "Ga je een AI-systeem of een AI-model op de markt brengen of in gebruik stellen onder eigen naam of merk, al dan niet tegen betaling?\nOf ben je een aanbieder van een AI-systeem, met inbegrip van een AI-systeem voor algemene doeleinden, waarin een AI-model is ge\xEFntegreerd, ongeacht of het AI-model door hemzelf wordt verstrekt en verticaal ge\xEFntegreerd is of door een andere entiteit wordt aangeboden op basis van contractuele betrekkingen?"
  questionType: SingleChoice
  answers:
  - answer: Ja
    result: 'Dan ben je een aanbieder volgens de AI verordening. Je bent een hoog risico AI systeem aan het ontwikkelen en je moet voldoen aan bepaalde vereisten van de AI-verordening (o.a. artikelen 4, 6, 9 t/m 21, 25, 40, 43, 47 t/m 50, 52, 60, 61, 72, 73)' # Bak C: hoog risico AI - bijlage I - aanbieder
    # moet je hier dan ook nog checken of je een gebruiksverantwoordelijke bent? Of is dat niet nodig?
  - answer: Nee
    nextQuestionId: '4.2.1'
- questionId: '4.2.1'
  question: Ben je een overheidsinstantie die een AI-systeem onder eigen verantwoordelijkheid gebruikt? Het AI-systeem wordt niet gebruikt in het kader van een persoonlijke niet-beroepsactiviteit
  questionType: SingleChoice
  answers:
  - answer: Ja
    nextQuestionId: '4.2.2'
  - answer: Nee
    result: "Deze beslisboom is gemaakt voor alleen deze twee rollen. Controleer nog een keer goed of \xE9\xE9n van deze rollen misschien toch op jou van toepassing is." # Bak D: hoog risico AI - bijlage I - geen aanbieder - geen gebruiksverantwoordelijke
- questionId: '4.2.2'
  question: Zet je jouw naam of merk op een AI-systeem met een hoog risico dat reeds in de handel is gebracht of in gebruik is gesteld, onverminderd contractuele regelingen waarin wordt bepaald dat de verplichtingen anders worden toegewezen
  questionType: SingleChoice
  answers:
  - answer: Ja
    result: Dan word je naast gebruiksverantwoordelijke ook beschouwd als een aanbieder van een AI-systeem met een hoog risico en ben je onderworpen aan de verplichtingen van de aanbieder uit hoofde van artikel 16. We raden je daarom aan de beslisboom nog een keer te doorlopen en daarbij aan te geven dat je een aanbieder van een AI-systeem met een hoog risico bent. # Bak E: hoog risico AI - bijlage I - gebruiksverantwoordelijke en beschouwd als aanbieder
  - answer: Nee
    nextQuestionId: '4.2.3'
- questionId: '4.2.3'
  question: "Breng je een substanti\xEBle wijziging aan in een AI-systeem met een hoog risico dat reeds in de handel is gebracht of reeds in gebruik is gesteld op zodanige wijze dat het systeem een AI-systeem met een hoog risico blijft op grond van artikel 6"
  questionType: SingleChoice
  answers:
  - answer: Ja
    result: Dan word je naast gebruiksverantwoordelijke ook beschouwd als een aanbieder van een AI-systeem met een hoog risico en ben je onderworpen aan de verplichtingen van de aanbieder uit hoofde van artikel 16. We raden je daarom aan de beslisboom nog een keer te doorlopen en daarbij aan te geven dat je een aanbieder van een AI-systeem met een hoog risico bent. # Bak E: hoog risico AI - bijlage I - gebruiksverantwoordelijke en beschouwd als aanbieder
  - answer: Nee
    nextQuestionId: '4.2.4'
- questionId: '4.2.4'
  question: Wijzig je het beoogde doel van een AI-systeem, met inbegrip van een AI-systeem voor algemene doeleinden, dat niet als een systeem met een hoog risico is geclassificeerd en reeds in de handel is gebracht of in gebruik is gesteld, op zodanige wijze dat het betrokken AI-systeem een AI-systeem met een hoog risico overeenkomstig artikel 6 wordt
  questionType: SingleChoice
  answers:
  - answer: Ja
    result: Dan word je naast gebruiksverantwoordelijke ook beschouwd als een aanbieder van een AI-systeem met een hoog risico en ben je onderworpen aan de verplichtingen van de aanbieder uit hoofde van artikel 16. We raden je daarom aan de beslisboom nog een keer te doorlopen en daarbij aan te geven dat je een aanbieder van een AI-systeem met een hoog risico bent. # Bak E: hoog risico AI - bijlage I - gebruiksverantwoordelijke en beschouwd als aanbieder
  - answer: Nee
    result: Dan word je alleen als gebruiksverantwoordelijke beschouwd en niet als een aanbieder van een AI-systeem met een hoog risico. # Bak F: hoog risico AI - bijlage I - gebruiksverantwoordelijke - geen aanbieder

### Hoog risico AI - toepassingsgebieden
- questionId: '5.0'
  question: Is je AI-systeem bedoeld om te worden gebruikt voor biometrische identificatie op afstand?
  questionType: SingleChoice
  answers:
  - answer: Ja
    answerComment: Je AI-systeem wordt waarschijnlijk beschouwd als een hoog-risico AI-systeem als het een significant risico op schade voor de gezondheid, veiligheid of de grondrechten van natuurlijke personen inhoudt. Het zou dan moeten voldoen aan bepaalde vereisten, afhankelijk van welke rol je hebt. Dit gaan we nu bepalen.
    nextQuestionId: '5.24.0'
  - answer: Nee
    nextQuestionId: '5.1'
- questionId: '5.1'
  question: Is je AI-systeem bedoeld om te worden gebruikt voor biometrische categorisering op basis van gevoelige of beschermde eigenschappen of kenmerken, of op basis van wat uit die eigenschappen of kenmerken wordt afgeleid?
  questionType: SingleChoice
  answers:
  - answer: Ja
    answerComment: Je AI-systeem wordt waarschijnlijk beschouwd als een hoog-risico AI-systeem als het een significant risico op schade voor de gezondheid, veiligheid of de grondrechten van natuurlijke personen inhoudt. Het zou dan moeten voldoen aan bepaalde vereisten, afhankelijk van welke rol je hebt. Dit gaan we nu bepalen.
    nextQuestionId: '5.24.0'
  - answer: Nee
    nextQuestionId: '5.2'
- questionId: '5.2'
  question: Is je AI-systeem bedoeld om te worden gebruikt als biometrische systeem voor emotieherkenning?
  questionType: SingleChoice
  answers:
  - answer: Ja
    answerComment: Je AI-systeem wordt waarschijnlijk beschouwd als een hoog-risico AI-systeem als het een significant risico op schade voor de gezondheid, veiligheid of de grondrechten van natuurlijke personen inhoudt. Het zou dan moeten voldoen aan bepaalde vereisten, afhankelijk van welke rol je hebt. Dit gaan we nu bepalen.
    nextQuestionId: '5.24.0'
  - answer: Nee
    nextQuestionId: '5.3'
- questionId: '5.3'
  question: Is je AI-systeem bedoeld om te worden gebruikt als veiligheidscomponent bij het beheer of de exploitatie van kritieke digitale infrastructuur, wegverkeer of bij de levering van water, gas, verwarming en elektriciteit?
  questionType: SingleChoice
  answers:
  - answer: Ja
    answerComment: Je AI-systeem wordt waarschijnlijk beschouwd als een hoog-risico AI-systeem als het een significant risico op schade voor de gezondheid, veiligheid of de grondrechten van natuurlijke personen inhoudt. Het zou dan moeten voldoen aan bepaalde vereisten, afhankelijk van welke rol je hebt. Dit gaan we nu bepalen.
    nextQuestionId: '5.24.0'
  - answer: Nee
    nextQuestionId: '5.4'
- questionId: '5.4'
  question: Is je AI-systeem bedoeld om te worden gebruikt voor het bepalen van toegang of toelating tot of het toewijzen van natuurlijke personen aan instellingen voor onderwijs en beroepsonderwijs op alle niveaus?
  questionType: SingleChoice
  answers:
  - answer: Ja
    answerComment: Je AI-systeem wordt waarschijnlijk beschouwd als een hoog-risico AI-systeem als het een significant risico op schade voor de gezondheid, veiligheid of de grondrechten van natuurlijke personen inhoudt. Het zou dan moeten voldoen aan bepaalde vereisten, afhankelijk van welke rol je hebt. Dit gaan we nu bepalen.
    nextQuestionId: '5.24.0'
  - answer: Nee
    nextQuestionId: '5.5'
- questionId: '5.5'
  question: Is je AI-systeem bedoeld om te worden gebruikt voor het evalueren van leerresultaten, ook wanneer die resultaten worden gebruikt voor het sturen van het leerproces van natuurlijke personen in instellingen voor onderwijs en beroepsonderwijs op alle niveaus?
  questionType: SingleChoice
  answers:
  - answer: Ja
    answerComment: Je AI-systeem wordt waarschijnlijk beschouwd als een hoog-risico AI-systeem als het een significant risico op schade voor de gezondheid, veiligheid of de grondrechten van natuurlijke personen inhoudt. Het zou dan moeten voldoen aan bepaalde vereisten, afhankelijk van welke rol je hebt. Dit gaan we nu bepalen.
    nextQuestionId: '5.24.0'
  - answer: Nee
    nextQuestionId: '5.6'
- questionId: '5.6'
  question: Is je AI-systeem bedoeld om te worden gebruikt voor het beoordelen van het passende onderwijsniveau dat een persoon zal ontvangen of waartoe hij toegang zal hebben, in het kader van of binnen instellingen voor onderwijs en beroepsonderwijs op alle niveaus?
  questionType: SingleChoice
  answers:
  - answer: Ja
    answerComment: Je AI-systeem wordt waarschijnlijk beschouwd als een hoog-risico AI-systeem als het een significant risico op schade voor de gezondheid, veiligheid of de grondrechten van natuurlijke personen inhoudt. Het zou dan moeten voldoen aan bepaalde vereisten, afhankelijk van welke rol je hebt. Dit gaan we nu bepalen.
    nextQuestionId: '5.24.0'
  - answer: Nee
    nextQuestionId: '5.7'
- questionId: '5.7'
  question: Is je AI-systeem bedoeld om te worden gebruikt voor het monitoren en detecteren van ongeoorloofd gedrag van studenten tijdens toetsen in de context van of binnen instellingen voor onderwijs en beroepsonderwijs op alle niveaus?
  questionType: SingleChoice
  answers:
  - answer: Ja
    answerComment: Je AI-systeem wordt waarschijnlijk beschouwd als een hoog-risico AI-systeem als het een significant risico op schade voor de gezondheid, veiligheid of de grondrechten van natuurlijke personen inhoudt. Het zou dan moeten voldoen aan bepaalde vereisten, afhankelijk van welke rol je hebt. Dit gaan we nu bepalen.
    nextQuestionId: '5.24.0'
  - answer: Nee
    nextQuestionId: '5.8'
- questionId: '5.8'
  question: Is je AI-systeem bedoeld om te worden gebruikt voor het werven of selecteren van natuurlijke personen, met name voor het plaatsen van gerichte vacatures, het analyseren en filteren van sollicitaties, en het beoordelen van kandidaten?
  questionType: SingleChoice
  answers:
  - answer: Ja
    answerComment: Je AI-systeem wordt waarschijnlijk beschouwd als een hoog-risico AI-systeem als het een significant risico op schade voor de gezondheid, veiligheid of de grondrechten van natuurlijke personen inhoudt. Het zou dan moeten voldoen aan bepaalde vereisten, afhankelijk van welke rol je hebt. Dit gaan we nu bepalen.
    nextQuestionId: '5.24.0'
  - answer: Nee
    nextQuestionId: '5.9'
- questionId: '5.9'
  question: "Is je AI-systeem bedoeld om te worden gebruikt voor het nemen van besluiten die van invloed zijn op de voorwaarden van arbeidsgerelateerde betrekkingen, de bevordering of be\xEBindiging van arbeidsgerelateerde contractuele betrekkingen, voor het toewijzen van taken op basis van individueel gedrag of persoonlijke eigenschappen of kenmerken, of voor het monitoren en evalueren van prestaties en gedrag van personen in dergelijke betrekkingen?"
  questionType: SingleChoice
  answers:
  - answer: Ja
    answerComment: Je AI-systeem wordt waarschijnlijk beschouwd als een hoog-risico AI-systeem als het een significant risico op schade voor de gezondheid, veiligheid of de grondrechten van natuurlijke personen inhoudt. Het zou dan moeten voldoen aan bepaalde vereisten, afhankelijk van welke rol je hebt. Dit gaan we nu bepalen.
    nextQuestionId: '5.24.0'
  - answer: Nee
    nextQuestionId: '5.10'
- questionId: '5.10'
  question: "Is je AI-systeem bedoeld om te worden gebruikt om te beoordelen of natuurlijke personen in aanmerking komen voor essenti\xEBle overheidsuitkeringen en -diensten, waaronder gezondheidsdiensten, of om dergelijke uitkeringen en diensten te verlenen, te beperken, in te trekken of terug te vorderen?"
  questionType: SingleChoice
  answers:
  - answer: Ja
    answerComment: Je AI-systeem wordt waarschijnlijk beschouwd als een hoog-risico AI-systeem als het een significant risico op schade voor de gezondheid, veiligheid of de grondrechten van natuurlijke personen inhoudt. Het zou dan moeten voldoen aan bepaalde vereisten, afhankelijk van welke rol je hebt. Dit gaan we nu bepalen.
    nextQuestionId: '5.24.0'
  - answer: Nee
    nextQuestionId: '5.11'
- questionId: '5.11'
  question: "Is je AI-systeem bedoeld om te worden gebruikt voor het beoordelen van de kredietwaardigheid van natuurlijke personen of voor het vaststellen van hun kredietscore, met uitzondering van AI-systemen die gebruikt worden om financi\xEBle fraude op te sporen?"
  questionType: SingleChoice
  answers:
  - answer: Ja
    answerComment: Je AI-systeem wordt waarschijnlijk beschouwd als een hoog-risico AI-systeem als het een significant risico op schade voor de gezondheid, veiligheid of de grondrechten van natuurlijke personen inhoudt. Het zou dan moeten voldoen aan bepaalde vereisten, afhankelijk van welke rol je hebt. Dit gaan we nu bepalen.
    nextQuestionId: '5.24.0'
  - answer: Nee
    nextQuestionId: '5.12'
- questionId: '5.12'
  question: Is je AI-systeem bedoeld om te worden gebruikt voor risicobeoordeling en prijsstelling met betrekking tot natuurlijke personen in het geval van levens- en ziektekostenverzekeringen?
  questionType: SingleChoice
  answers:
  - answer: Ja
    answerComment: Je AI-systeem wordt waarschijnlijk beschouwd als een hoog-risico AI-systeem als het een significant risico op schade voor de gezondheid, veiligheid of de grondrechten van natuurlijke personen inhoudt. Het zou dan moeten voldoen aan bepaalde vereisten, afhankelijk van welke rol je hebt. Dit gaan we nu bepalen.
    nextQuestionId: '5.24.0'
  - answer: Nee
    nextQuestionId: '5.13'
- questionId: '5.13'
  question: "Is je AI-systeem bedoeld om noodoproepen van natuurlijke personen te evalueren en te classificeren of om te worden gebruikt voor het inzetten of het bepalen van prioriteiten voor de inzet van hulpdiensten, onder meer van politie, brandweer en ambulance, alsook van systemen voor de triage van pati\xEBnten die dringend medische zorg behoeven?"
  questionType: SingleChoice
  answers:
  - answer: Ja
    answerComment: Je AI-systeem wordt waarschijnlijk beschouwd als een hoog-risico AI-systeem als het een significant risico op schade voor de gezondheid, veiligheid of de grondrechten van natuurlijke personen inhoudt. Het zou dan moeten voldoen aan bepaalde vereisten, afhankelijk van welke rol je hebt. Dit gaan we nu bepalen.
    nextQuestionId: '5.24.0'
  - answer: Nee
    nextQuestionId: '5.14'
- questionId: '5.14'
  question: Is je AI-systeem bedoeld om door of namens rechtshandhavingsinstanties, of door instellingen, organen of instanties van de Unie ter ondersteuning van rechtshandhavingsinstanties of namens hen, te worden gebruikt om het risico te beoordelen dat een natuurlijke persoon het slachtoffer wordt van strafbare feiten?
  questionType: SingleChoice
  answers:
  - answer: Ja
    answerComment: Je AI-systeem wordt waarschijnlijk beschouwd als een hoog-risico AI-systeem als het een significant risico op schade voor de gezondheid, veiligheid of de grondrechten van natuurlijke personen inhoudt. Het zou dan moeten voldoen aan bepaalde vereisten, afhankelijk van welke rol je hebt. Dit gaan we nu bepalen.
    nextQuestionId: '5.24.0'
  - answer: Nee
    nextQuestionId: '5.15'
- questionId: '5.15'
  question: Is je AI-systeem bedoeld om door of namens rechtshandhavingsinstanties of door instellingen, organen of instanties van de Unie ter ondersteuning van rechtshandhavingsinstanties te worden gebruikt als leugendetector of soortgelijke instrumenten?
  questionType: SingleChoice
  answers:
  - answer: Ja
    answerComment: Je AI-systeem wordt waarschijnlijk beschouwd als een hoog-risico AI-systeem als het een significant risico op schade voor de gezondheid, veiligheid of de grondrechten van natuurlijke personen inhoudt. Het zou dan moeten voldoen aan bepaalde vereisten, afhankelijk van welke rol je hebt. Dit gaan we nu bepalen.
    nextQuestionId: '5.24.0'
  - answer: Nee
    nextQuestionId: '5.16'
- questionId: '5.16'
  question: Is je AI-systeem bedoeld om door of namens rechtshandhavingsinstanties of door instellingen, organen of instanties van de Unie ter ondersteuning van rechtshandhavingsinstanties te worden gebruikt om de betrouwbaarheid van bewijsmateriaal tijdens het onderzoek naar of de vervolging van strafbare feiten te beoordelen?
  questionType: SingleChoice
  answers:
  - answer: Ja
    answerComment: Je AI-systeem wordt waarschijnlijk beschouwd als een hoog-risico AI-systeem als het een significant risico op schade voor de gezondheid, veiligheid of de grondrechten van natuurlijke personen inhoudt. Het zou dan moeten voldoen aan bepaalde vereisten, afhankelijk van welke rol je hebt. Dit gaan we nu bepalen.
    nextQuestionId: '5.24.0'
  - answer: Nee
    nextQuestionId: '5.17'
- questionId: '5.17'
  question: Is je AI-systeem bedoeld om door of namens rechtshandhavingsinstanties of door instellingen, organen of instanties van de Unie ter ondersteuning van rechtshandhavingsinstanties te worden gebruikt om te beoordelen hoe groot het risico is dat een natuurlijke persoon (opnieuw) een strafbaar feit zal plegen, niet uitsluitend op basis van profilering van natuurlijke personen als bedoeld in artikel 3, punt 4, van Richtlijn (EU) 2016/680, of om persoonlijkheidskenmerken en eigenschappen of eerder crimineel gedrag van natuurlijke personen of groepen te beoordelen?
  questionType: SingleChoice
  answers:
  - answer: Ja
    answerComment: Je AI-systeem wordt waarschijnlijk beschouwd als een hoog-risico AI-systeem als het een significant risico op schade voor de gezondheid, veiligheid of de grondrechten van natuurlijke personen inhoudt. Het zou dan moeten voldoen aan bepaalde vereisten, afhankelijk van welke rol je hebt. Dit gaan we nu bepalen.
    nextQuestionId: '5.24.0'
  - answer: Nee
    nextQuestionId: '5.18'
- questionId: '5.18'
  question: Is je AI-systeem bedoeld om door of namens rechtshandhavingsinstanties of door instellingen, organen en instanties van de Unie ter ondersteuning van rechtshandhavingsinstanties te worden gebruikt om natuurlijke personen te profileren als bedoeld in artikel 3, punt 4, van Richtlijn (EU) 2016/680, tijdens het opsporen, onderzoeken of vervolgen van strafbare feiten?
  questionType: SingleChoice
  answers:
  - answer: Ja
    answerComment: Je AI-systeem wordt waarschijnlijk beschouwd als een hoog-risico AI-systeem als het een significant risico op schade voor de gezondheid, veiligheid of de grondrechten van natuurlijke personen inhoudt. Het zou dan moeten voldoen aan bepaalde vereisten, afhankelijk van welke rol je hebt. Dit gaan we nu bepalen.
    nextQuestionId: '5.24.0'
  - answer: Nee
    nextQuestionId: '5.19'
- questionId: '5.19'
  question: Is je AI-systeem bedoeld om door of namens bevoegde overheidsinstanties of door instellingen, organen of instanties van de Unie te worden gebruikt als leugendetector of soortgelijke hulpmiddelen?
  questionType: SingleChoice
  answers:
  - answer: Ja
    answerComment: Je AI-systeem wordt waarschijnlijk beschouwd als een hoog-risico AI-systeem als het een significant risico op schade voor de gezondheid, veiligheid of de grondrechten van natuurlijke personen inhoudt. Het zou dan moeten voldoen aan bepaalde vereisten, afhankelijk van welke rol je hebt. Dit gaan we nu bepalen.
    nextQuestionId: '5.24.0'
  - answer: Nee
    nextQuestionId: '5.20'
- questionId: '5.20'
  question: "Is je AI-systeem bedoeld om door of namens bevoegde overheidsinstanties of door instellingen, organen of instanties van de Unie te worden gebruikt om risico\u2019s te beoordelen, waaronder een veiligheidsrisico, een risico op illegale migratie of een gezondheidsrisico, uitgaat van een natuurlijke persoon die voornemens is het grondgebied van een lidstaat te betreden of dat heeft gedaan?"
  questionType: SingleChoice
  answers:
  - answer: Ja
    answerComment: Je AI-systeem wordt waarschijnlijk beschouwd als een hoog-risico AI-systeem als het een significant risico op schade voor de gezondheid, veiligheid of de grondrechten van natuurlijke personen inhoudt. Het zou dan moeten voldoen aan bepaalde vereisten, afhankelijk van welke rol je hebt. Dit gaan we nu bepalen.
    nextQuestionId: '5.24.0'
  - answer: Nee
    nextQuestionId: '5.21'
- questionId: '5.21'
  question: Is je AI-systeem bedoeld om door of namens bevoegde overheidsinstanties  of door instellingen, organen of instanties van de Unie te worden gebruikt om bevoegde overheidsinstanties bij te staan bij de behandeling van aanvragen voor asiel, visa of verblijfsvergunningen en bij de behandeling van aanverwante klachten in verband met het al dan niet in aanmerking komen van de natuurlijke personen die een aanvraag voor een status indienen, met inbegrip van hieraan gerelateerde beoordelingen van de betrouwbaarheid van bewijsmateriaal?
  questionType: SingleChoice
  answers:
  - answer: Ja
    answerComment: Je AI-systeem wordt waarschijnlijk beschouwd als een hoog-risico AI-systeem als het een significant risico op schade voor de gezondheid, veiligheid of de grondrechten van natuurlijke personen inhoudt. Het zou dan moeten voldoen aan bepaalde vereisten, afhankelijk van welke rol je hebt. Dit gaan we nu bepalen.
    nextQuestionId: '5.24.0'
  - answer: Nee
    nextQuestionId: '5.22'
- questionId: '5.22'
  question: Is je AI-systeem bedoeld om door of namens bevoegde overheidsinstanties, of door instellingen, organen of instanties van de Unie, te worden gebruikt in het kader van migratie-, asiel- of grenstoezichtsbeheer, met het oog op het opsporen, herkennen of identificeren van natuurlijke personen, met uitzondering van de verificatie van reisdocumenten?
  questionType: SingleChoice
  answers:
  - answer: Ja
    answerComment: Je AI-systeem wordt waarschijnlijk beschouwd als een hoog-risico AI-systeem als het een significant risico op schade voor de gezondheid, veiligheid of de grondrechten van natuurlijke personen inhoudt. Het zou dan moeten voldoen aan bepaalde vereisten, afhankelijk van welke rol je hebt. Dit gaan we nu bepalen.
    nextQuestionId: '5.24.0'
  - answer: Nee
    nextQuestionId: '5.23'
- questionId: '5.23'
  question: Is je AI-systeem bedoeld om door of namens een gerechtelijke instantie te worden gebruikt om een gerechtelijke instantie te ondersteunen bij het onderzoeken en uitleggen van feiten of de wet en bij de toepassing van het recht op een concrete reeks feiten of om te worden gebruikt op soortgelijke wijze in het kader van alternatieve geschillenbeslechting?
  questionType: SingleChoice
  answers:
  - answer: Ja
    answerComment: Je AI-systeem wordt waarschijnlijk beschouwd als een hoog-risico AI-systeem als het een significant risico op schade voor de gezondheid, veiligheid of de grondrechten van natuurlijke personen inhoudt. Het zou dan moeten voldoen aan bepaalde vereisten, afhankelijk van welke rol je hebt. Dit gaan we nu bepalen.
    nextQuestionId: '5.24.0'
  - answer: Nee
    nextQuestionId: '5.24'
- questionId: '5.24'
  question: "Is je AI-systeem bedoeld voor het be\xEFnvloeden van de uitslag van een verkiezing of referendum of van het stemgedrag van natuurlijke personen bij de uitoefening van hun stemrecht bij verkiezingen of referenda? Dit geldt niet voor AI-systemen aan de output waarvan natuurlijke personen niet rechtstreeks worden blootgesteld, zoals instrumenten die worden gebruikt om politieke campagnes te organiseren, te optimaliseren of te structureren vanuit administratief of logistiek oogpunt."
  questionType: SingleChoice
  answers:
  - answer: Ja
    answerComment: Je AI-systeem wordt waarschijnlijk beschouwd als een hoog-risico AI-systeem als het een significant risico op schade voor de gezondheid, veiligheid of de grondrechten van natuurlijke personen inhoudt. Het zou dan moeten voldoen aan bepaalde vereisten, afhankelijk van welke rol je hebt. Dit gaan we nu bepalen.
    nextQuestionId: '5.24.0'
  - answer: Nee
    answerComment: Het blijkt dat je AI-systeem niet verboden is en geen hoog risico AI-systeem is. Het kan echter zijn dat het wel aan bepaalde transparantieverplichtingen moet voldoen ([link naar art. 50 transparantieverplichtingen]).\nWe gaan nu eerst bepalen wat voor rol je hebt.
    nextQuestionId: '8.0'

### check rol hoog risico AI - toepassingsgebieden
- questionId: '5.24.0'
  question: "Ga je een AI-systeem of een AI-model op de markt brengen of in gebruik stellen onder eigen naam of merk, al dan niet tegen betaling?\nOf ben je een aanbieder van een AI-systeem, met inbegrip van een AI-systeem voor algemene doeleinden, waarin een AI-model is ge\xEFntegreerd, ongeacht of het AI-model door hemzelf wordt verstrekt en verticaal ge\xEFntegreerd is of door een andere entiteit wordt aangeboden op basis van contractuele betrekkingen?"
  questionType: SingleChoice
  answers:
  - answer: Ja
    answerComment: "Dan ben je een aanbieder volgens de AI verordening.\nJe bent een hoog risico AI systeem aan het ontwikkelen en je moet voldoen aan bepaalde vereisten van de AI-verordening (o.a. artikelen 4, 6, 9 t/m 21, 25, 40, 43, 47 t/m 50, 52, 60, 61, 72, 73). Ga door naar de volgende vragen om te bepalen of je hoog risico AI-systeem valt onder één van de uitzonderingen"
    nextQuestionId: '5.24.0.0'
  - answer: Nee
    answerComment: "Je bent geen aanbieder. We gaan kijken of je mogelijk een andere rol hebt"
    nextQuestionId: '5.24.1'
- questionId: '5.24.1'
  question: "Ben je een overheidsinstantie die een AI-systeem onder eigen verantwoordelijkheid gebruikt? Het AI-systeem wordt niet gebruikt in het kader van een persoonlijke niet-beroepsactiviteit"
  questionType: SingleChoice
  answers:
  - answer: Ja
    answerComment: "Dan ben je een gebruiksverantwoordelijke volgens de AI verordening.\nJe bent verantwoordelijk voor het gebruik van een hoog risico AI systeem en je moet voldoen aan bepaalde vereisten van de AI-verordening (o.a. artikelen 12, 25 t/m 27, 49, 50, 86). Let op! Er zijn omstandigheden waaronder je als gebruiksverantwoordelijke beschouwd wordt als een aanbieder van een AI-systeem met een hoog risico. We gaan nu vaststellen of dat het geval is."
    nextQuestionId: '5.24.2'
  - answer: Nee
    result: "Je bent geen gebruiksverantwoordelijke en geen aanbieder. Deze beslisboom is gemaakt voor alleen deze twee rollen. Controleer nog een keer goed of één van deze rollen misschien toch op jou van toepassing is." # Bak G: hoog risico AI - toepassingsgebieden - geen aanbieder - geen gebruiksverantwoordelijke
##### check of je wordt beschouwd als aanbieder
- questionId: '5.24.2'
  question: "Zet je jouw naam of merk op een AI-systeem met een hoog risico dat reeds in de handel is gebracht of in gebruik is gesteld, onverminderd contractuele regelingen waarin wordt bepaald dat de verplichtingen anders worden toegewezen"
  questionType: SingleChoice
  answers:
  - answer: Ja
    result: "Dan word je naast gebruiksverantwoordelijke ook beschouwd als een aanbieder van een AI-systeem met een hoog risico en ben je onderworpen aan de verplichtingen van de aanbieder uit hoofde van artikel 16. We raden je daarom aan de beslisboom nog een keer te doorlopen en daarbij aan te geven dat je een aanbieder van een AI-systeem met een hoog risico bent." # Bak H: hoog risico AI - toepassingsgebieden - gebruiksverantwoordelijke en beschouwd als aanbieder
  - answer: Nee
    nextQuestionId: '5.24.3'
- questionId: '5.24.3'
  question: "Breng je een substantiële wijziging aan in een AI-systeem met een hoog risico dat reeds in de handel is gebracht of reeds in gebruik is gesteld op zodanige wijze dat het systeem een AI-systeem met een hoog risico blijft op grond van artikel 6"
  questionType: SingleChoice
  answers:
  - answer: Ja
    result: "Dan word je naast gebruiksverantwoordelijke ook beschouwd als een aanbieder van een AI-systeem met een hoog risico en ben je onderworpen aan de verplichtingen van de aanbieder uit hoofde van artikel 16. We raden je daarom aan de beslisboom nog een keer te doorlopen en daarbij aan te geven dat je een aanbieder van een AI-systeem met een hoog risico bent." # Bak H: hoog risico AI - toepassingsgebieden - gebruiksverantwoordelijke en beschouwd als aanbieder
  - answer: Nee
    nextQuestionId: '5.24.4'
- questionId: '5.24.4'
  question: "Wijzig je het beoogde doel van een AI-systeem, met inbegrip van een AI-systeem voor algemene doeleinden, dat niet als een systeem met een hoog risico is geclassificeerd en reeds in de handel is gebracht of in gebruik is gesteld, op zodanige wijze dat het betrokken AI-systeem een AI-systeem met een hoog risico overeenkomstig artikel 6 wordt"
  questionType: SingleChoice
  answers:
  - answer: Ja
    result: "Dan word je naast gebruiksverantwoordelijke ook beschouwd als een aanbieder van een AI-systeem met een hoog risico en ben je onderworpen aan de verplichtingen van de aanbieder uit hoofde van artikel 16. We raden je daarom aan de beslisboom nog een keer te doorlopen en daarbij aan te geven dat je een aanbieder van een AI-systeem met een hoog risico bent." # Bak H: hoog risico AI - toepassingsgebieden - gebruiksverantwoordelijke en beschouwd als aanbieder
  - answer: Nee
    result: "Dan word je alleen als gebruiksverantwoordelijke beschouwd en niet als een aanbieder van een AI-systeem met een hoog risico" # Bak I: hoog risico AI - toepassingsgebieden - gebruiksverantwoordelijke - geen aanbieder

### check uitzonderingen hoog risico - toepassingsgebieden
- questionId: '5.24.0.0'
  question: Is het AI-systeem bedoeld om een beperkte procedurele taak uit te voeren en is er geen significant risico op schade voor de gezondheid, veiligheid of de grondrechten van natuurlijke personen?
  questionType: SingleChoice
  answers:
  - answer: Ja
    nextQuestionId: '5.24.0.0.1'
  - answer: Nee
    nextQuestionId: '5.24.0.2'
- questionId: '5.24.0.2'
  question: Is het AI-systeem bedoeld om het resultaat van een eerder voltooide menselijke activiteit te verbeteren en bevat het systeem geen significant risico op schade voor de gezondheid, veiligheid of de grondrechten van natuurlijke personen?
  questionType: SingleChoice
  answers:
  - answer: Ja
    nextQuestionId: '5.24.0.0.1'
  - answer: Nee
    nextQuestionId: '5.24.0.3'
- questionId: '5.24.0.3'
  question: "Is het AI-systeem bedoeld om besluitvormingspatronen of afwijkingen van eerdere besluitvormingspatronen op te sporen en is het niet bedoeld om de eerder voltooide menselijke beoordeling zonder behoorlijke menselijke toetsing te vervangen of te be\xEFnvloeden?"
  questionType: SingleChoice
  answers:
  - answer: Ja
    nextQuestionId: '5.24.0.0.1'
  - answer: Nee
    nextQuestionId: '5.24.0.4'
- questionId: '5.24.0.4'
  question: Is het AI-systeem bedoeld om een voorbereidende taak uit te voeren voor een beoordeling die relevant is voor de in bijlage III vermelde gebruiksgevallen?
  questionType: SingleChoice
  answers:
  - answer: Ja
    nextQuestionId: '5.24.0.0.1'
  - answer: Nee
    answerComment: "Je systeem valt niet onder de uitzondering en het blijft beschouwd als een hoog risico AI systeem. Het kan echter zijn dat het wel aan bepaalde transparantieverplichtingen moet voldoen ([link naar art. 50 transparantieverplichtingen])"
    nextQuestionId: '6.0'
- questionId: '5.24.0.0.1'
  question: Voert het AI-systeem profilering van natuurlijke personen uit?
  questionType: SingleChoice
  answers:
  - answer: Nee
    answerComment: "Het is mogelijk dat je AI-systeem toch geen hoog-risico systeem is. Het kan echter zijn dat het wel aan bepaalde transparantieverplichtingen moet voldoen ([link naar art. 50 transparantieverplichtingen])"
    nextQuestionId: '6.0' # OPM: dit verwijst naar dezelfde vraag?
  - answer: Ja
    answerComment: "Je AI-systeem wordt waarschijnlijk beschouwd als een hoog-risico AI-systeem. Het zou dan moeten voldoen aan bepaalde vereisten. Het kan echter zijn dat het ook aan bepaalde transparantieverplichtingen moet voldoen ([link naar art. 50 transparantieverplichtingen])"
    nextQuestionId: '6.0' # OPM: dit verwijst naar dezelfde vraag?

### Transparantievereisten aanbieders
- questionId: '6.0'
  question: Ontwikkel je AI-systemen die voor directe interactie met natuurlijke personen zijn bedoeld?
  questionType: SingleChoice
  answers:
  - answer: Ja
    result: Dan moet je voldoen aan de transparantieverplichtingen van art. 50(1). # Bak
  - answer: Nee
    nextQuestionId: '6.1'
- questionId: '6.1'
  question: Ontwikkel je AI-systemen, met inbegrip van AI-systemen voor algemene doeleinden die synthetische audio-, beeld-, video- of tekstinhoud genereren? # we zaten toch in niet genAI tak?
  questionType: SingleChoice
  answers:
  - answer: Ja
    result: Dan moet je voldoen aan de transparantieverplichtingen van art. 50(2).
  - answer: Nee
    result: Dan hoef je niet te voldoen aan de transparantieverplichtingen. Houd je wel aan bestaande wet- en regelgeving (bijv. AVG wanneer je persoonsgegevens verwerkt) # moeten we hier nog checken of je moet publiceren in het register?

### check rol bij general purpose AI
- questionId: '7.0'
  question: "Ga je een AI-systeem of een AI-model op de markt brengen of in gebruik stellen onder eigen naam of merk, al dan niet tegen betaling?\nOf ben je een aanbieder van een AI-systeem, met inbegrip van een AI-systeem voor algemene doeleinden, waarin een AI-model is geïntegreerd, ongeacht of het AI-model door hemzelf wordt verstrekt en verticaal geïntegreerd is of door een andere entiteit wordt aangeboden op basis van contractuele betrekkingen?"
  questionType: SingleChoice
  answers:
  - answer: Ja
    answerComment: "Dan ben je een aanbieder volgens de AI verordening.\nJe bent een AI systeem voor algemene doeleinden aan het ontwikkelen en je moet voldoen aan bepaalde vereisten van de AI-verordening (o.a. artikelen 4, 50 t/m 55)"
    nextQuestionId: '7.1'
  - answer: Nee
    answerComment: "Je bent geen aanbieder. We gaan checken of je een andere rol hebt."
    nextQuestionId: '7.2'
- questionId: '7.1'
  question: "Ben je een aanbieder van een AI-systeem voor algemene doeleinden met een systeemrisico? (Volgens artikel 51 beschikt een AI-systeem met een systeemrisico over capaciteiten met een grote impact die worden geëvalueerd op basis van passende technische instrumenten en methoden, met inbegrip van  indicatoren en benchmarks. Daarnaast wordt geacht capaciteiten met een grote impact overeenkomstig lid 1, punt a), te hebben wanneer de cumulatieve hoeveelheid berekeningen die wordt gebruikt om het model te trainen, gemeten in zwevendekommabewerkingen, groter is dan 10^25)"
  questionType: SingleChoice
  answers:
  - answer: Ja
    result: "Je AI-systeem moet voldoen aan de vereisten van artikel 55 van de AI-verordening. Let op: het kan zijn dat je ook aan de transparantieverplichtingen van artikel 50 moet voldoen."  # Bak N: general purpose AI - aanbieder - systeemrisico
  - answer: Nee
    result: "Dan ben je een AI systeem voor algemene doeleinden aan het ontwikkelen en je moet voldoen de vereisten van artikel 53. Let op: het kan zijn dat je ook aan de transparantieverplichtingen van artikel 50 moet voldoen." # Bak O: general purpose AI - aanbieder - geen systeemrisico
    # moeten we hier nog verder naar vragen voor transparantieverplichtingen?
- questionId: '7.2'
  question: "Ben je een overheidsinstantie die een AI-systeem onder eigen verantwoordelijkheid gebruikt? Het AI-systeem wordt niet gebruikt in het kader van een persoonlijke niet-beroepsactiviteit"
  questionType: SingleChoice
  answers:
  - answer: Ja
    result: "Dan ben je een gebruiksverantwoordelijke volgens de AI verordening. Als je een AI-systeem voor algemene doeleinden gebruikt dan moet je nog steeds voldoen aan artikel 25, 27, 50, 86." # Bak P: general purpose AI - geen aanbieder - gebruiksverantwoordelijke
  - answer: Nee
    result: "Je bent geen aanbieder en geen gebruiksverantwoordelijke. Deze beslisboom is gemaakt voor alleen deze twee rollen. Controleer nog een keer goed of één van deze rollen misschien toch op jou van toepassing is." # Bak Q: general purpose AI - geen aanbieder - geen gebruiksverantwoordelijke

### Transparantieverplichtingen geen hoog risico
- questionId: '8.0'
  question: Ga je een AI-systeem of een AI-model op de markt brengen of in gebruik stellen onder eigen naam of merk, al dan niet tegen betaling?\nOf ben je een aanbieder van een AI-systeem, met inbegrip van een AI-systeem voor algemene doeleinden, waarin een AI-model is geïntegreerd, ongeacht of het AI-model door hemzelf wordt verstrekt en verticaal geïntegreerd is of door een andere entiteit wordt aangeboden op basis van contractuele betrekkingen?
  questionType: SingleChoice
  answers:
  - answer: Ja
    answerComment: "Dan ben je een aanbieder volgens de AI verordening."
    nextQuestionId: '6.0'
  - answer: Nee
    answerComment: "Je bent geen aanbieder. We gaan kijken of je een andere rol hebt."
    nextQuestionId: '8.1'
- questionId: '8.1'
  question: Ben je een overheidsinstantie die een AI-systeem onder eigen verantwoordelijkheid gebruikt? Het AI-systeem wordt niet gebruikt in het kader van een persoonlijke niet-beroepsactiviteit
  questionType: SingleChoice
  answers:
  - answer: Ja
    nextQuestionId: '8.2'
  - answer: Nee
    result: "Je bent geen aanbieder en geen gebruiksverantwoordelijke. Deze beslisboom is gemaakt voor alleen deze twee rollen. Controleer nog een keer goed of één van deze rollen misschien toch op jou van toepassing is." # Bak R: niet verboden - niet hoog risico - geen aanbieder - geen gebruiksverantwoordelijke
- questionId: '8.2'
  question: Ontwikkel je AI-systemen voor het herkennen van emoties of een systeem voor biometrische categorisering
  questionType: SingleChoice
  answers:
  - answer: Ja
    result: Dan moet je voldoen aan de transparantieverplichtingen van art. 50(3).
  - answer: Nee
    nextQuestionId: '8.3'
- questionId: '8.3'
  question: Ontwikkel je AI-systemen dat beeld-, audio- of videocontent genereert of die een deepfake vormt bewerkt?
  questionType: SingleChoice
  answers:
  - answer: Ja
    result: Dan moet je voldoen aan de transparantieverplichtingen van art. 50(4)
  - answer: Nee
    nextQuestionId: '8.4'
- questionId: '8.4'
  question: Ontwikkel je AI-systemen die tekst genereren of bewerken en die worden gepubliceerd om het publiek te informeren over aangelegenheden van algemeen belang?
  questionType: SingleChoice
  answers:
  - answer: Ja
    result: Dan moet je voldoen aan de transparantieverplichtingen van art. 50(4)
  - answer: Nee
    result: Dan hoef je niet te voldoen aan de transparantieverplichtingen. Houd je wel aan bestaande wet- en regelgeving (bijv. AVG wanneer je persoonsgegevens verwerkt) # hier nog checken of je wel moet publiceren in register?

### Buiten scope AI-verordening
- questionId: '9.0'
  question: De AI-verordening is niet van toepassing. Gebruik je een algoritme met impact (rechtsgevolgen voor de burger of classificatie van burgers of groepen)? Volgens categorie B van de handreiking van het algoritmeregister
  questionType: SingleChoice
  answers:
  - answer: Ja
    nextQuestionId: '9.1'
  - answer: Nee
    result: Je algoritme is niet impactvol en de AI-verordening is niet van toepassing. Houd je wel aan bestaande wet- en regelgeving (bijv. AVG wanneer je persoonsgegevens verwerkt) # bak W: AI verordening niet van toepassing - niet impactvol
- questionId: '9.1'
  question: "Valt je toepassing onder \xE9\xE9n van de uitzonderingsgronden categorie C of D van de handreiking?"
  questionType: SingleChoice
  answers:
  - answer: Ja
    result: Het betreft een algoritme met impact, maar de AI-verordening is niet van toepassing. Je hoeft vanwege uitzonderingsgrond niet te publiceren in het register # bak X: AI verordening niet van toepassing - impactvol maar niet publiceren vanwege uitzonderingsgrond
  - answer: Nee
    result: Het betreft een algoritme met impact, maar de AI-verordening is niet van toepassing. Je moet wel publiceren in het algoritmeregister # bak Y: AI verordening niet van toepassing - impactvol
